---
title: "Linear regression with a single predictor"
subtitle: "Lecture 4"
date: "February 10, 2025"
format: 
  revealjs:
    footer: "[https://bovi-analytics.github.io/BeastsAndBytes/](https://bovi-analytics.github.io/BeastsAndBytes/)"
---

# Warm up

```{r}
#| echo: false
#| message: false

library(countdown)
library(tidyverse)
ggplot2::theme_set(theme_gray(base_size = 16))
```

## Goals

-   Modeling with a single predictor
-   Model parameters, estimates, and error terms
-   Interpreting slopes and intercepts

## Setup

```{r}
#| label: load-pkg
#| message: false

library(dplyr)
library(tidyverse)
library(tidymodels)
```

# Correlation vs. causation

## Spurious correlations

![](images/mozarella-ce-phd.png){fig-align="center"}

::: aside
Source: [tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations)
:::

## Spurious correlations

![](images/pool-nick-cage.png){fig-align="center"}

::: aside
Source: [tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations)
:::

# Linear regression with a single predictor

## Read the data

```{r data-read}
#| echo: true

df_raw_cattle_numbers <- read.csv('https://raw.githubusercontent.com/Bovi-analytics/minor-digital-agriculture/refs/heads/main/data/fao-cattle-numbers.csv')
```

## Data prep

-   Select columns needed : `Year` and `Value`
-   Apply correct FAIR naming convention

```{r data-prep-1}
#| echo: true

df_cattle_numbers <- df_raw_cattle_numbers %>%
  dplyr::select(Year, Value) %>%
  dplyr::rename(
    NumberOfCows = Value
  )
```

## Data grouping

-   Create a groupby `Year`
-   Create sum for entire world

```{r data-prep-2}
#| echo: true

df_total_cattle_numbers <- df_cattle_numbers %>%
  dplyr::group_by(Year) %>%
  dplyr::summarise(
    TotalNumberOfCows = sum(NumberOfCows)/1000000000
  )
```

## Writing the data

-   Write the data to csv
-   Import in Tableau

```{r data-write}
#| echo: true

write_csv(df_total_cattle_numbers, file = "df_total_cattle_numbers.csv")
```

## Data overview

```{r data-overview}
#| echo: true

df_total_cattle_numbers %>%
  select(Year, TotalNumberOfCows)
```

## Data visualization

```{r}
#| echo: false

ggplot(df_total_cattle_numbers, 
       aes(x = Year, y = TotalNumberOfCows)) +
  geom_point(alpha = 0.5) + 
  labs(
    x = "Year" , 
    y = "Total Number of Cows"
  )
```

## Regression model {#regression-model-1}

A **regression model** is a function that describes the relationship between the outcome, $Y$, and the predictor, $X$.

$$\begin{aligned} Y &= \color{black}{\textbf{Model}} + \text{Error} \\[8pt]
&= \color{black}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{black}{\boldsymbol{\mu_{Y|X}}} + \epsilon \end{aligned}$$

## Regression model

::::: columns
::: {.column width="30%"}
$$
\begin{aligned} Y &= \color{#325b74}{\textbf{Model}} + \text{Error} \\[8pt]
&= \color{#325b74}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{#325b74}{\boldsymbol{\mu_{Y|X}}} + \epsilon 
\end{aligned}
$$
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| message: false

m <- lm(TotalNumberOfCows ~ Year, data = df_total_cattle_numbers)
ggplot(data = df_total_cattle_numbers, 
       mapping = aes(x = Year, y = TotalNumberOfCows)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "#325b74", se = FALSE, linewidth = 1.5) +
  labs(x = "X", y = "Y") +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.ticks.x = element_blank(), 
    axis.ticks.y = element_blank()
    )
```
:::
:::::

## Simple linear regression {.smaller}

Use **simple linear regression** to model the relationship between a quantitative outcome ($Y$) and a single quantitative predictor ($X$): $$\Large{Y = \beta_0 + \beta_1 X + \epsilon}$$

::: incremental
-   $\beta_1$: True slope of the relationship between $X$ and $Y$
-   $\beta_0$: True intercept of the relationship between $X$ and $Y$
-   $\epsilon$: Error (residual)
:::

## Simple linear regression

$$\Large{\hat{Y} = b_0 + b_1 X}$$

-   $b_1$: Estimated slope of the relationship between $X$ and $Y$
-   $b_0$: Estimated intercept of the relationship between $X$ and $Y$
-   No error term!

## Choosing values for $b_1$ and $b_0$

```{r}
#| echo: false
#| message: false

ggplot(data = df_total_cattle_numbers, 
       mapping = aes(x = Year, y = TotalNumberOfCows)) +
  geom_point(alpha = 0.4) + 
  geom_abline(intercept = -1.615e+01, slope = 8.785e-03, color = "#325b74", linewidth = 1.5) +
  geom_abline(intercept = -1.615e+01, slope = 9.785e-04, color = "gray") +
  geom_abline(intercept = -1.615e+01, slope = 8.785e-03, color = "gray") +
  geom_abline(intercept = -1.615e+01, slope = 8.785e-03, color = "gray") +
  labs(x = "Year", y = "Total number of cows")
```

## Residuals

```{r}
#| message: false
#| echo: false
#| fig-align: center

ggplot(data = df_total_cattle_numbers, 
       mapping = aes(x = Year, y = TotalNumberOfCows)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "#325b74", se = FALSE, linewidth = 1.5) +
  geom_segment(aes(x = Year, xend = Year, y = TotalNumberOfCows, yend = predict(m)), color = "steel blue") +
  labs(x = "Critics Score", y = "Audience Score") +
  theme(legend.position = "none")
```

$$\text{residual} = \text{observed} - \text{predicted} = y - \hat{y}$$

## Least squares line {.smaller}

-   The residual for the $i^{th}$ observation is

$$e_i = \text{observed} - \text{predicted} = y_i - \hat{y}_i$$

-   The **sum of squared** residuals is

$$e^2_1 + e^2_2 + \dots + e^2_n$$

-   The **least squares line** is the one that **minimizes the sum of squared residuals**

## Least squares line

```{r}
cows_fit <- linear_reg() |>
  fit(TotalNumberOfCows ~ Year, data = df_total_cattle_numbers)

tidy(cows_fit)
```

# Slope and intercept

## Properties of least squares regression

::: incremental
-   The regression line goes through the center of mass point (the coordinates corresponding to average $X$ and average $Y$): $b_0 = \bar{Y} - b_1~\bar{X}$

-   Slope has the same sign as the correlation coefficient: $b_1 = r \frac{s_Y}{s_X}$

-   Sum of the residuals is zero: $\sum_{i = 1}^n \epsilon_i = 0$

-   Residuals and $X$ values are uncorrelated
:::

## Interpreting the slope {.smaller}

:::: panel-tabset
## Question

::: poll
The slope of the model for predicting number of cows is 0.008785434.
:::

How to interpret

## Submit

```{=html}
<iframe allowfullscreen frameborder="0" height="100%" mozallowfullscreen style="min-width: 500px; min-height: 355px" src="https://app.wooclap.com/STA199S24?from=status-bar?" width="100%"></iframe>
```
::::

## Interpreting slope & intercept

$$\widehat{\text{Total number of cows}} = -16.1 + 0.008785434    \times \text{Year}$$

::: incremental
-   **Slope:** For every one point increase in `Year`, we expect the total number of cows to be higher by 0.008785434 points, on average.
-   **Intercept:** In `Year` is 0, we expect the total number of cows to be -16.1.
:::

## Is the intercept meaningful?

âœ… The intercept is meaningful in context of the data if

-   the predictor can feasibly take values equal to or near zero or
-   the predictor has values near zero in the observed data

. . .

ðŸ›‘ Otherwise, it might not be meaningful!
